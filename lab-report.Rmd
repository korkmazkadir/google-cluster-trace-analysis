---
title: "Google Cluster Trace Analysis with Apache Spark"
output:
  pdf_document: default
  html_document: default
---

In this work, I analysed [Google cluster-usage traces](https://github.com/google/cluster-data/blob/master/ClusterData2011_2.md) using Apache Spark and I created the document using R Studio.

You can access the subject of this work from [this](https://tropars.github.io/downloads/lectures/LSDM/LSDM-lab-spark-google.pdf) link.
You can find the detailed documantatin of traces from [this](https://drive.google.com/file/d/0B5g07T_gRDg9Z0lsSTEtTWtpOW8/view)  link.

**This version of the code does not contains the Spark codes which are used to extract information from the traces also this is not the final version. There is no guarante related to correctness of the results.**

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(gridExtra)
library(grid)
library(data.table)
library(ggplot2)

formatNumber<-function(number){
  return(format(number, big.mark=","))
}

formatDataFrame<-function(df){
  return(format.data.frame(df, big.mark=","))
}

```

\pagebreak

#1. Machine Distibution
## Machine Distibution According to CPU and Memory Capacity

```{r echo=FALSE}
library(ggplot2)
library(ggExtra)
library(knitr)

machineDistribution = 
  read.csv("./result/question-1/machine-dist-cpu-memory-capacity.csv", header = TRUE)


p=ggplot(machineDistribution, aes(x=cpu, y=memory, color=cpu, size=number_of_machines, label=number_of_machines)) +
      geom_point() + 
      geom_text(aes(label=number_of_machines),hjust=0, size=4, nudge_x= 0.025) +
      theme(legend.position="none") 

p +  scale_x_continuous(breaks=c(0.25,0.5,1)) + scale_y_continuous(breaks=unique(machineDistribution$memory))

kable(machineDistribution,caption = "Tabular Data")

```

\pagebreak

## Machine Distibution According to Platform
```{r echo=FALSE}

machineDistribution = 
  read.csv("./result/question-1/machine-dist-platform.csv", header = TRUE)

kable(machineDistribution)

```


#2. Job and Task Counts


```{r, echo=FALSE}
jobTaskCount = 
  read.csv("./result/question-2/job-task-count.csv", header = TRUE)

df <- data.frame(
  "number_of_jobs" = c(formatNumber( nrow(jobTaskCount) )), 
  "number_of_tasks" = c(formatNumber( sum(jobTaskCount$task_count) )),
  "avg_number_of_task_count" = c(formatNumber( mean(jobTaskCount$task_count) ))
  )

kable(df)

summary<-summary(jobTaskCount$task_count)

summaryDF <- data.frame(unclass(summary), check.names = FALSE, stringsAsFactors = FALSE)
colnames(summaryDF)<- c("statistics")

kable(summaryDF)

```


#3. Job/Task Life Cycle Analysis (Killed and Evicted Job/Task)


```{r, echo=FALSE}
priorityLifeCycleStats = 
  read.csv("./result/question-3/priority-task-life-cycle.csv", header = TRUE)

colnames(priorityLifeCycleStats)[colnames(priorityLifeCycleStats) == 'evicted_task_count'] <- 'evicted_count'
colnames(priorityLifeCycleStats)[colnames(priorityLifeCycleStats) == 'failed_task_count'] <- 'failed_count'
colnames(priorityLifeCycleStats)[colnames(priorityLifeCycleStats) == 'killed_task_count'] <- 'killed_count'
colnames(priorityLifeCycleStats)[colnames(priorityLifeCycleStats) == 'lost_task_count'] <- 'lost_count'
colnames(priorityLifeCycleStats)[colnames(priorityLifeCycleStats) == 'distinct_task_count'] <- 'task_count'

priorityLifeCycleStats$evicted_percent = round( priorityLifeCycleStats$evicted_count * 100 / priorityLifeCycleStats$task_count, 1 )
priorityLifeCycleStats$failed_percent =  round( priorityLifeCycleStats$failed_count * 100 / priorityLifeCycleStats$task_count, 1 )
priorityLifeCycleStats$killed_percent =  round( priorityLifeCycleStats$killed_count * 100 / priorityLifeCycleStats$task_count, 1 )
priorityLifeCycleStats$lost_percent =  round( priorityLifeCycleStats$lost_count * 100 / priorityLifeCycleStats$task_count, 1 )

#kable( formatDataFrame( priorityLifeCycleStats[,c("priority", "evicted_count", "failed_count", "killed_count", "lost_count", "task_count")]))
kable( formatDataFrame( priorityLifeCycleStats[,c("priority","killed_percent", "evicted_percent", "failed_percent", "lost_percent", "task_count")]) )


```


#4. Eviction Probability of Tasks with Respect to Priority

You can look the table of the question 3 to conclude about this.


#5. Relation between the Priority of a Task and Machine Resources(CPU, Memory)
