---
title: "Google Cluster Trace Analysis with Apache Spark"
output:
  pdf_document: default
  html_document: default
---

In this work, I analysed [Google cluster-usage traces](https://github.com/google/cluster-data/blob/master/ClusterData2011_2.md) using Apache Spark and I created the document using R Studio.

You can access the subject of this work from [this](https://tropars.github.io/downloads/lectures/LSDM/LSDM-lab-spark-google.pdf) link.
You can find the detailed documantatin of traces from [this](https://drive.google.com/file/d/0B5g07T_gRDg9Z0lsSTEtTWtpOW8/view)  link.

**This version of the code does not contains the Spark codes which are used to extract information from the traces also this is not the final version. There is no guarante related to correctness of the results.**

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(gridExtra)
library(grid)
library(data.table)
library(ggplot2)

formatNumber<-function(number){
  return(format(number, big.mark=","))
}

formatDataFrame<-function(df){
  return(format.data.frame(df, big.mark=","))
}

```

\pagebreak

#1. Machine Distibution
## Machine Distibution According to CPU and Memory Capacity

```{r echo=FALSE}
library(ggplot2)
library(ggExtra)
library(knitr)

machineDistribution = 
  read.csv("./result/question-1/machine-dist-cpu-memory-capacity.csv", header = TRUE)


p=ggplot(machineDistribution, aes(x=cpu, y=memory, color=cpu, size=number_of_machines, label=number_of_machines)) +
      geom_point() + 
      geom_text(aes(label=number_of_machines),hjust=0, size=4, nudge_x= 0.025) +
      theme(legend.position="none") 

p +  scale_x_continuous(breaks=c(0.25,0.5,1)) + scale_y_continuous(breaks=unique(machineDistribution$memory))

kable(machineDistribution,caption = "Tabular Data")

```

\pagebreak

## Machine Distibution According to Platform
```{r echo=FALSE}

machineDistribution = 
  read.csv("./result/question-1/machine-dist-platform.csv", header = TRUE)

kable(machineDistribution)

```


#2. Job and Task Counts


```{r, echo=FALSE}
jobTaskCount = 
  read.csv("./result/question-2/job-task-count.csv", header = TRUE)

df <- data.frame(
  "number_of_jobs" = c(formatNumber( nrow(jobTaskCount) )), 
  "number_of_tasks" = c(formatNumber( sum(jobTaskCount$task_count) )),
  "avg_number_of_task_count" = c(formatNumber( mean(jobTaskCount$task_count) ))
  )

kable(df)

summary<-summary(jobTaskCount$task_count)

summaryDF <- data.frame(unclass(summary), check.names = FALSE, stringsAsFactors = FALSE)
colnames(summaryDF)<- c("statistics")

kable(summaryDF)

```


#3. Job/Task Life Cycle Analysis (Killed and Evicted Job/Task)


```{r, echo=FALSE}
priorityLifeCycleStats = 
  read.csv("./result/question-3/priority-task-life-cycle.csv", header = TRUE)

colnames(priorityLifeCycleStats)[colnames(priorityLifeCycleStats) == 'evicted_task_count'] <- 'evicted_count'
colnames(priorityLifeCycleStats)[colnames(priorityLifeCycleStats) == 'failed_task_count'] <- 'failed_count'
colnames(priorityLifeCycleStats)[colnames(priorityLifeCycleStats) == 'killed_task_count'] <- 'killed_count'
colnames(priorityLifeCycleStats)[colnames(priorityLifeCycleStats) == 'lost_task_count'] <- 'lost_count'
colnames(priorityLifeCycleStats)[colnames(priorityLifeCycleStats) == 'distinct_task_count'] <- 'task_count'

priorityLifeCycleStats$evicted_percent = round( priorityLifeCycleStats$evicted_count * 100 / priorityLifeCycleStats$task_count, 1 )
priorityLifeCycleStats$failed_percent =  round( priorityLifeCycleStats$failed_count * 100 / priorityLifeCycleStats$task_count, 1 )
priorityLifeCycleStats$killed_percent =  round( priorityLifeCycleStats$killed_count * 100 / priorityLifeCycleStats$task_count, 1 )
priorityLifeCycleStats$lost_percent =  round( priorityLifeCycleStats$lost_count * 100 / priorityLifeCycleStats$task_count, 1 )

#kable( formatDataFrame( priorityLifeCycleStats[,c("priority", "evicted_count", "failed_count", "killed_count", "lost_count", "task_count")]))
kable( formatDataFrame( priorityLifeCycleStats[,c("priority","killed_percent", "evicted_percent", "failed_percent", "lost_percent", "task_count")]) )


```


#4. Eviction Probability of Tasks with Respect to Priority

You can look the table of the question 3 to conclude about this.


#5. Relation between the Priority of a Task and Machine Resources(CPU, Memory)

```{r echo=FALSE}
library(ggplot2)
library(ggExtra)
library(knitr)


priorityCapacityDataset = 
  read.csv("./result/question-5/priority-machine-capacity-relation.csv", header = TRUE)


# p=ggplot(priorityCapacityDataset, aes(x=capacity, y=priority, size=task_count, label=task_count)) +
#       geom_point() + 
#       #geom_text(aes(label=task_count),hjust=0, size=4, nudge_x= 0.025) +
#       theme(legend.position="none", axis.text.x = element_text(angle = 50, hjust = 1)) 
# 
# p +  scale_x_continuous(breaks=priorityCapacityDataset$capacity) + 
#   scale_y_continuous(breaks=unique(priorityCapacityDataset$priority))

taskCountByPriority <- aggregate(priorityCapacityDataset$task_count, by=list(Category=priorityCapacityDataset$priority), FUN=sum)

colnames(taskCountByPriority) <- c("priority","total_task_count")

#kable( formatDataFrame( taskCountByPriority ), caption="Task count by priority")

machineDistribution = 
  read.csv("./result/question-1/machine-dist-cpu-memory-capacity.csv", header = TRUE)
#kable(machineDistribution[,c("capacity","cpu", "memory", "machine_percentage")], caption="Machine distribution by capacity")


priorityCapacityDataset <- merge(priorityCapacityDataset, taskCountByPriority, by = "priority")

priorityCapacityDataset$task_percentage = round( priorityCapacityDataset$task_count * 100 /  priorityCapacityDataset$total_task_count, 1 ) 

#Makes disceret axis
priorityCapacityDataset$capacity <- as.character(priorityCapacityDataset$capacity)
priorityCapacityDataset$priority <- as.character(priorityCapacityDataset$priority)

#Order Values numerically
priorityCapacityDataset$priority <- factor(priorityCapacityDataset$priority, levels = c("0","1","2","3","4","5","6","7","8","9","10","11"))

ggplot(data = priorityCapacityDataset, aes(x = capacity, y = priority)) +
  geom_tile(aes(fill = task_percentage), colour = "white") +
  geom_text(aes(label=task_percentage),size=2,color="linen") +
  theme(legend.position="none",axis.text.x = element_text(angle = 50, hjust = 1), panel.grid.major  = element_blank(),  panel.grid.minor  = element_blank())
```



```{r results='asis', echo=FALSE}
    # Setting `results = 'asis'` allows for using Latex within the code chunk
    cat('\\begin{center}')
    # `{c c}` Creates a two column table
    # Use `{c | c}` if you'd like a line between the tables
    cat('\\begin{tabular}{ c c }')
    print(knitr::kable( formatDataFrame( taskCountByPriority ), format = 'latex'))
    # Separate the two columns with an `&`
    cat('&')
    print(knitr::kable(machineDistribution[,c("capacity","cpu", "memory", "machine_percentage")], format = 'latex'))
    cat('\\end{tabular}')
    cat('\\end{center}')
```

From heatmap and machine distribution data we can conclude that tasks are uniformly distributed on machines.



#7. Tasks consumes significantly less resource than what they requested

```{r results='asis', echo=FALSE}

bins <- c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100)

memoryConsumption <- c(9403495, 162321, 212388, 488168, 528610, 594301, 829299, 598128, 485174, 514702, 602390, 509211, 521277, 507115, 512200, 559509, 624598, 661028, 796245, 1051587)

cpuComnsumprion <- c(11828731, 3196895, 1439782, 1691237, 685753, 321222, 225548, 168018, 123777, 106177, 69096, 142918, 36677, 17153, 17901, 19113, 15198, 15081, 22789, 18680)

consumptionDF <- data.frame(
  "percentage"= c(2.5, 7.5, 12.5, 17.5, 22.5, 27.5, 32.5, 37.5, 42.5, 47.5, 52.5, 57.5, 62.5, 67.5, 72.5, 77.5, 82.5, 87.5, 92.5, 97.5),
  "memory_consumption" = c(9403495, 162321, 212388, 488168, 528610, 594301, 829299, 598128, 485174, 514702, 602390, 509211, 521277, 507115, 512200, 559509, 624598, 661028, 796245, 1051587),
  "cpu_consumption" = c(11828731, 3196895, 1439782, 1691237, 685753, 321222, 225548, 168018, 123777, 106177, 69096, 142918, 36677, 17153, 17901, 19113, 15198, 15081, 22789, 18680)
)


ggplot(consumptionDF, aes(x=percentage, y=memory_consumption)) +
  geom_bar(stat="identity") + scale_x_continuous(breaks=c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100)) 

ggplot(consumptionDF, aes(x=percentage, y=cpu_consumption)) +
  geom_bar(stat="identity") + scale_x_continuous(breaks=c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100)) 


```

Adding some text :)




